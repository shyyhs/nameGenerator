{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from io import open\n",
    "import unicodedata\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "import math\n",
    "import glob\n",
    "\n",
    "#torch\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#use \"$export CUDA_VISIBLE_DEVICES=2,3,...\" to assign GPU\n",
    "#device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small Functions\n",
    "\n",
    "def toTensor(tokLst):#tokLst: a numpy or python list of numbers\n",
    "    return torch.tensor(tokLst, dtype=torch.long, device=device)\n",
    "\n",
    "def randomTrainingData(tNames):\n",
    "    tName= tNames[random.randint(0,len(tNames)-1)]\n",
    "    inputT = toTensor(tName[:-1])\n",
    "    targetT = toTensor(tName[1:])\n",
    "    return inputT,targetT\n",
    "\n",
    "def stringLstReverse(stringLst):\n",
    "    return [s[::-1] for s in stringLst]\n",
    "\n",
    "def reverseNameGenerate(fileName):\n",
    "    baseName= (os.path.basename(fileName))\n",
    "    dirName = os.path.dirname(fileName)\n",
    "    revFileName = dirName+'/'+baseName+'.reverse'\n",
    "    revFile = open(revFileName,'w')\n",
    "    file = open(fileName,'r')\n",
    "    for line in file:\n",
    "        revFile.write(line[:-1][::-1]+'\\n')\n",
    "    file.close()\n",
    "    revFile.close()\n",
    "    return revFileName\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,inputSize,hiddenSize,outputSize):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hiddenSize=hiddenSize\n",
    "        self.inputSize=inputSize\n",
    "        self.layerN=2\n",
    "        self.embedding = nn.Embedding(inputSize, hiddenSize)\n",
    "        self.gru=nn.GRU(hiddenSize,hiddenSize,num_layers=2)\n",
    "        self.o2o=nn.Linear(hiddenSize,outputSize)\n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "        self.softmax=nn.LogSoftmax(dim=1)\n",
    "    def forward(self,input,hidden):\n",
    "        inputEmbedding = self.embedding(input.view(-1,1)).view(1, 1, -1)\n",
    "        inputEmbedding = F.relu(inputEmbedding)\n",
    "        output,hidden=self.gru(inputEmbedding,hidden)\n",
    "        output=self.o2o(output)\n",
    "        output=output[0]\n",
    "        output=self.dropout(output)\n",
    "        output=self.softmax(output)\n",
    "        return output,hidden\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.layerN,1,self.hiddenSize,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nameGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nameGenerator():\n",
    "    def dataInit(self,fileName):\n",
    "        nameFile = open(fileName,'r')\n",
    "        self.c2n={}\n",
    "        self.n2c={}\n",
    "        self.c2n[\"EOS\"]=0\n",
    "        self.n2c[0]=\"EOS\"\n",
    "        self.c2n[\"SOS\"]=1\n",
    "        self.n2c[1]=\"SOS\"\n",
    "        self.nowIdx=1\n",
    "        self.totChar=2\n",
    "        self.names=[] #For example names[0]==['b',c,d]\n",
    "        self.tNames=[] #Corresponding example: tNames[0]=[0,3,9,2,1] \n",
    "        \n",
    "        for line in nameFile:\n",
    "            name=[]\n",
    "            tName=[]\n",
    "            tName.append(self.c2n[\"SOS\"])\n",
    "            for c in line:\n",
    "                if (self.c2n.get(c)==None):\n",
    "                    self.nowIdx+=1\n",
    "                    self.totChar+=1\n",
    "                    self.c2n[c]=self.nowIdx\n",
    "                    self.n2c[self.nowIdx]=c\n",
    "                if (c!='\\n'):\n",
    "                    name.append(c)\n",
    "                    tName.append(self.c2n[c])\n",
    "            tName.append(self.c2n[\"EOS\"])\n",
    "            self.names.append(name)\n",
    "            self.tNames.append(tName)\n",
    "            \n",
    "    def modelInit(self):\n",
    "        self.nn=RNN(self.totChar,self.hiddenSize,self.totChar)\n",
    "        if (device!=torch.device(\"cpu\")):\n",
    "            self.nn.cuda()\n",
    "            \n",
    "    def trainInit(self):\n",
    "        self.optimizer = optim.Adagrad(self.nn.parameters())\n",
    "        self.criterion=nn.NLLLoss()\n",
    "        \n",
    "        self.print_avgLoss=[]\n",
    "        \n",
    "    def parameterInit(self):\n",
    "        self.iterN=10000\n",
    "        self.hiddenSize=128\n",
    "        self.maxLen=12\n",
    "        self.sampleNumber=15\n",
    "        \n",
    "        self.printEveryIter=200\n",
    "        self.startTime=time.time()\n",
    "        \n",
    "    def __init__(self,fileName):\n",
    "        self.parameterInit()\n",
    "        self.dataInit(fileName)\n",
    "        self.modelInit()\n",
    "        self.trainInit()\n",
    "        \n",
    "    def print(self):\n",
    "        plt.figure()\n",
    "        plt.plot(self.print_avgLoss)\n",
    "        \n",
    "    def trainOneIter(self,inputT,targetT):\n",
    "        targetT.unsqueeze_(-1)\n",
    "\n",
    "        loss=0\n",
    "        hidden=self.nn.initHidden()\n",
    "        for i in range(inputT.size(0)):\n",
    "            output,hidden=self.nn(inputT[i],hidden)\n",
    "            loss+=self.criterion(output,targetT[i])\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return output,loss.item()/inputT.size(0)\n",
    "    \n",
    "    def train(self):\n",
    "        totLoss=0\n",
    "        for iter in range(1,self.iterN+1):\n",
    "            output,loss=self.trainOneIter(*randomTrainingData(self.tNames))\n",
    "            totLoss+=loss\n",
    "            if (iter%self.printEveryIter==0):\n",
    "                avgLoss= (totLoss/self.printEveryIter)\n",
    "                print(\"Training Time:{}, recentAvgLoss:{}\".\n",
    "                      format(time.time()-self.startTime,avgLoss))\n",
    "                totLoss=0\n",
    "                self.print_avgLoss.append(avgLoss)\n",
    "                \n",
    "    def sample(self,prefix=''):\n",
    "        with torch.no_grad():\n",
    "            tPrefix=[self.c2n['SOS']]\n",
    "            for c in prefix:\n",
    "                tPrefix.append(self.c2n[c])\n",
    "            inputT = toTensor(tPrefix)\n",
    "\n",
    "            hidden = self.nn.initHidden()\n",
    "            outputName=prefix\n",
    "            for i in range(inputT.size(0)-1):\n",
    "                output,hidden=self.nn(inputT[i],hidden)\n",
    "            for i in range(self.maxLen):\n",
    "                output,hidden=self.nn(inputT[-1],hidden)\n",
    "                topv,topi=output.topk(1)\n",
    "                topi=topi[0][0].item()\n",
    "                if (topi==self.c2n[\"EOS\"]):\n",
    "                    break\n",
    "                else:\n",
    "                    outputName+=self.n2c[topi]\n",
    "                inputT=toTensor([topi])\n",
    "        return outputName\n",
    "    def samples(self,prefix):\n",
    "        resLst = [self.sample(prefix) for i in range(self.sampleNumber)]\n",
    "        return list(set(resLst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time:10.68100118637085, recentAvgLoss:4.660944073276259\n",
      "Training Time:20.737584829330444, recentAvgLoss:4.326226436856733\n",
      "Training Time:31.186752796173096, recentAvgLoss:4.13232210641754\n",
      "Training Time:41.29770517349243, recentAvgLoss:4.143534831193001\n",
      "Training Time:51.93019890785217, recentAvgLoss:4.0261269794189305\n",
      "Training Time:61.46187925338745, recentAvgLoss:4.00006734861346\n",
      "Training Time:70.9291422367096, recentAvgLoss:3.9698389890539034\n",
      "Training Time:80.9633252620697, recentAvgLoss:4.022328131714199\n",
      "Training Time:91.49183773994446, recentAvgLoss:3.9198448987652563\n",
      "Training Time:101.12189793586731, recentAvgLoss:3.8000759224826237\n",
      "Training Time:110.83234119415283, recentAvgLoss:3.7977832250576204\n",
      "Training Time:120.73055052757263, recentAvgLoss:3.8728533792958895\n",
      "Training Time:130.8252763748169, recentAvgLoss:3.802310164366982\n",
      "Training Time:140.3080472946167, recentAvgLoss:3.761312135333915\n",
      "Training Time:150.31414461135864, recentAvgLoss:3.7404744504613374\n",
      "Training Time:159.62061834335327, recentAvgLoss:3.7175798626580105\n",
      "Training Time:169.67506670951843, recentAvgLoss:3.784158481131318\n",
      "Training Time:179.1712372303009, recentAvgLoss:3.683282972162262\n",
      "Training Time:189.32566022872925, recentAvgLoss:3.626663335125366\n",
      "Training Time:199.65073013305664, recentAvgLoss:3.804134189088174\n",
      "Training Time:208.97875499725342, recentAvgLoss:3.637410178593677\n",
      "Training Time:219.03493285179138, recentAvgLoss:3.6592702418783096\n",
      "Training Time:229.20305681228638, recentAvgLoss:3.676039338356104\n",
      "Training Time:239.18568468093872, recentAvgLoss:3.619330194806803\n",
      "Training Time:248.98776817321777, recentAvgLoss:3.649134174924179\n",
      "Training Time:259.0745735168457, recentAvgLoss:3.639910380556552\n",
      "Training Time:269.21307158470154, recentAvgLoss:3.5530645873062956\n",
      "Training Time:279.9761040210724, recentAvgLoss:3.5876903763286903\n",
      "Training Time:290.3603961467743, recentAvgLoss:3.567595422214859\n",
      "Training Time:300.70905661582947, recentAvgLoss:3.606256764439613\n",
      "Training Time:311.1710321903229, recentAvgLoss:3.547056084262808\n",
      "Training Time:322.05816102027893, recentAvgLoss:3.535707667939158\n",
      "Training Time:332.30383253097534, recentAvgLoss:3.4959433119673546\n",
      "Training Time:342.28208899497986, recentAvgLoss:3.50392558388536\n",
      "Training Time:351.7153103351593, recentAvgLoss:3.5062722442976724\n",
      "Training Time:361.4732437133789, recentAvgLoss:3.5196228357884256\n",
      "Training Time:371.2193377017975, recentAvgLoss:3.488463981378166\n",
      "Training Time:380.906302690506, recentAvgLoss:3.5024510444910426\n",
      "Training Time:390.68164443969727, recentAvgLoss:3.366706438428078\n",
      "Training Time:400.74155020713806, recentAvgLoss:3.504787462419218\n",
      "Training Time:410.25658440589905, recentAvgLoss:3.432053186623457\n",
      "Training Time:420.5665867328644, recentAvgLoss:3.4937170452789075\n",
      "Training Time:431.299147605896, recentAvgLoss:3.3983284036617243\n",
      "Training Time:441.5550374984741, recentAvgLoss:3.467975431166916\n",
      "Training Time:451.68584418296814, recentAvgLoss:3.4285740912695513\n",
      "Training Time:461.72244906425476, recentAvgLoss:3.368322463198447\n",
      "Training Time:471.6187448501587, recentAvgLoss:3.4775072391836908\n",
      "Training Time:481.91645073890686, recentAvgLoss:3.363057346221156\n",
      "Training Time:492.0588130950928, recentAvgLoss:3.3780843210286133\n",
      "Training Time:502.1505832672119, recentAvgLoss:3.4124805407108543\n",
      "Training Time:9.663920402526855, recentAvgLoss:4.6327493993747515\n",
      "Training Time:19.08087992668152, recentAvgLoss:4.363335587114061\n",
      "Training Time:28.76274085044861, recentAvgLoss:4.061647933952688\n",
      "Training Time:38.56272220611572, recentAvgLoss:4.047891296779269\n",
      "Training Time:49.08345317840576, recentAvgLoss:3.998996273935699\n",
      "Training Time:59.324235677719116, recentAvgLoss:3.9346681347943657\n",
      "Training Time:69.17727589607239, recentAvgLoss:3.9273908856618602\n",
      "Training Time:79.16139960289001, recentAvgLoss:3.9743570060391678\n",
      "Training Time:88.64733934402466, recentAvgLoss:3.874989641811697\n",
      "Training Time:98.74910354614258, recentAvgLoss:3.854561570317259\n",
      "Training Time:109.10868525505066, recentAvgLoss:3.8653921740196604\n",
      "Training Time:119.61243057250977, recentAvgLoss:3.7681913778875757\n",
      "Training Time:129.60484981536865, recentAvgLoss:3.770644897253461\n",
      "Training Time:139.251713514328, recentAvgLoss:3.750894304673699\n",
      "Training Time:149.5986888408661, recentAvgLoss:3.7206256661039117\n",
      "Training Time:159.41900777816772, recentAvgLoss:3.803762674129643\n",
      "Training Time:169.0845091342926, recentAvgLoss:3.7516389605871687\n",
      "Training Time:179.46312069892883, recentAvgLoss:3.5742006992821094\n",
      "Training Time:189.4619197845459, recentAvgLoss:3.7336388995140846\n",
      "Training Time:199.28018260002136, recentAvgLoss:3.6459170097919134\n",
      "Training Time:209.03163528442383, recentAvgLoss:3.6664908109146013\n",
      "Training Time:218.98769426345825, recentAvgLoss:3.6634279306771123\n",
      "Training Time:228.84683847427368, recentAvgLoss:3.6666749229681233\n"
     ]
    }
   ],
   "source": [
    "originalFileName = \"./data/names/twitter.txt\"\n",
    "reverseFileName = reverseNameGenerate(originalFileName)\n",
    "\n",
    "nameGenerator1 = nameGenerator(originalFileName)\n",
    "nameGenerator1.train()\n",
    "nameGenerator1.print()\n",
    "nameGenerator2 = nameGenerator(reverseFileName)\n",
    "nameGenerator2.train()\n",
    "nameGenerator2.print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testString=''\n",
    "print (nameGenerator1.samples(testString))\n",
    "print (stringLstReverse(nameGenerator2.samples(testString[::-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
